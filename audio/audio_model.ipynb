{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAg2--y2IZX8",
        "outputId": "b1e2304a-d91f-46df-c272-06a269db9534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9DnvZzZIUKQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "#특징 추출기 불러오기( 완전연결계층 X / input_shape 또한 따로 특정되지 않음 / 사전 훈련 x )\n",
        "res_url = 'https://tfhub.dev/tensorflow/efficientnet/lite4/classification/2'\n",
        "feature_model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(res_url, \n",
        "                   output_shape=(1000,), \n",
        "                   trainable=False)\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwGlevo_Rq6a",
        "outputId": "c3726916-209c-4af0-e615-7df33d7431a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feature_model.build([None, 224, 224, 3])\n",
        "feature_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1000)              13118936  \n",
            "=================================================================\n",
            "Total params: 13,118,936\n",
            "Trainable params: 0\n",
            "Non-trainable params: 13,118,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwSqhNxuXhU0"
      },
      "source": [
        "feature_model.save('/content/drive/My Drive/efficientnet_feature.h5')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_TL9Z7fIhJD",
        "outputId": "f064c3c8-2581-472c-a8ec-213518a007d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "\n",
        "image_size = 500\n",
        "batch_size = 32\n",
        "\n",
        "# 학습 및 검증 데이터용 ImageDataGenerator 생성해 놓기 \n",
        "train_datagen = ImageDataGenerator(rescale=1./255., \n",
        "                                   validation_split = 0.25)\n",
        "\n",
        "#검증데이터는 정규화 외에 따로 조정 없음 \n",
        "valid_datagen = ImageDataGenerator(rescale=1./255., \n",
        "                                   validation_split = 0.25)\n",
        "\n",
        "#flow_from_directory()는 앞서 배운 flow()와 비슷, 단 경로를 통채로 가져올 수 있음 \n",
        "train_generator = train_datagen.flow_from_directory(directory = '/content/drive/My Drive/mel_spectrogram', #저장 경로 \n",
        "                                                    subset = 'training',   \n",
        "                                                    batch_size = batch_size,\n",
        "                                                    seed = 126,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (image_size,image_size))\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory = '/content/drive/My Drive/mel_spectrogram',\n",
        "                                                    subset = 'validation',\n",
        "                                                    batch_size = 1,\n",
        "                                                    seed = 126,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (image_size,image_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1323 images belonging to 2 classes.\n",
            "Found 441 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGNN-SPqRwGE",
        "outputId": "4fb4f456-4cc1-463f-bbb8-0babab2122c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 학습데이터의 3배정도 이미지가 보강되도록 한다.\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "batch_step = (1764 * 2) // batch_size #데이터 증폭 시켜 배치 스텝을 구해준다.(723회)\n",
        "train_features = [] # 빈 리스트 생성 \n",
        "train_Y = [] # 빈 리스트 생성 \n",
        "\n",
        "for idx in tqdm(range(batch_step)): #스텝 만큼 반복\n",
        "  x, y = train_generator.next() #next()를 활용하여 train_generator에 담겨진 [[입력픽셀],[라벨링]] 을 x와 y에 담아 준다.   \n",
        "  train_Y.extend(y) #append()와 비슷한 기능, list에 appending 수행\n",
        "  \n",
        "  # feature_model : 이미 학습이 완료된 특징 추출기 (우리가 불러옴)\n",
        "  # 학습데이터 x 를 활용해서 feature_model을 통과시켜 특징 추출.\n",
        "  feature = feature_model.predict(x)\n",
        "  train_features.extend(feature)\n",
        "\n",
        "#array 전환 \n",
        "train_features = np.array(train_features)\n",
        "train_Y = np.array(train_Y)\n",
        "\n",
        "print(train_features.shape)\n",
        "print(train_Y.shape)\n",
        "print(train_Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:13<00:00,  1.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3478, 1000)\n",
            "(3478, 2)\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2SFrfzcSIlq",
        "outputId": "4e39c60e-e4db-4696-e550-4d753c5a853b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_features = [] # 빈 리스트 생성 \n",
        "valid_Y = [] # 빈 리스트 생성 \n",
        "\n",
        "for idx in tqdm(range(valid_generator.n)): ## valid_generator.n = 2504 (검증데이터의 수)\n",
        "  x, y = valid_generator.next() #next()를 활용하여 valid_generator에 담겨진 [[입력픽셀],[라벨링]] 을 x와 y에 담아 준다.   \n",
        "  valid_Y.extend(y) #append()와 비슷한 기능, list에 appending 수행\n",
        "  \n",
        "  # feature_model : 이미 학습이 완료된 특징 추출기 (우리가 불러옴)\n",
        "  # 학습데이터 x 를 활용해서 feature_model을 통과시켜 특징 추출.\n",
        "  feature = feature_model.predict(x)\n",
        "  valid_features.extend(feature)\n",
        "\n",
        "#array 전환 \n",
        "valid_features = np.array(valid_features)\n",
        "valid_Y = np.array(valid_Y)\n",
        "\n",
        "print(valid_features.shape)\n",
        "print(valid_Y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 441/441 [00:24<00:00, 17.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(441, 1000)\n",
            "(441, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjKJFL4Iihx",
        "outputId": "c9cb9449-ab74-4f5f-c92c-7d5353f7015d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(256, activation= 'relu', input_shape = (1000,)),\n",
        "                             tf.keras.layers.Dropout(0.5),\n",
        "                             tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "model.compile(tf.optimizers.RMSprop(0.0001), \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EgXhczHSpwo",
        "outputId": "49d30b18-4c2f-4f37-9c8a-ba81aec15c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint_path = '/content/drive/My Drive/check.h5'\n",
        "\n",
        "cp = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                save_weights_only=True,\n",
        "                                save_best_only=True,\n",
        "                                monitor='val_accuracy',\n",
        "                                verbose=1)\n",
        "\n",
        "es = EarlyStopping(patience=50, verbose=1)\n",
        "history = model.fit(train_features, train_Y, \n",
        "                    validation_data=(valid_features, valid_Y),\n",
        "                    epochs = 100,\n",
        "                    batch_size = 32,\n",
        "                    callbacks=[es,cp])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8741\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92290, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8749 - val_loss: 0.1681 - val_accuracy: 0.9229\n",
            "Epoch 2/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9413\n",
            "Epoch 00002: val_accuracy improved from 0.92290 to 0.94104, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9413 - val_loss: 0.1320 - val_accuracy: 0.9410\n",
            "Epoch 3/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9540\n",
            "Epoch 00003: val_accuracy improved from 0.94104 to 0.95465, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9540 - val_loss: 0.1084 - val_accuracy: 0.9546\n",
            "Epoch 4/100\n",
            "101/109 [==========================>...] - ETA: 0s - loss: 0.1004 - accuracy: 0.9626\n",
            "Epoch 00004: val_accuracy improved from 0.95465 to 0.97052, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9638 - val_loss: 0.0946 - val_accuracy: 0.9705\n",
            "Epoch 5/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 0.0886 - accuracy: 0.9648\n",
            "Epoch 00005: val_accuracy did not improve from 0.97052\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9655 - val_loss: 0.0883 - val_accuracy: 0.9705\n",
            "Epoch 6/100\n",
            " 89/109 [=======================>......] - ETA: 0s - loss: 0.0740 - accuracy: 0.9723\n",
            "Epoch 00006: val_accuracy did not improve from 0.97052\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9727 - val_loss: 0.0773 - val_accuracy: 0.9683\n",
            "Epoch 7/100\n",
            " 87/109 [======================>.......] - ETA: 0s - loss: 0.0616 - accuracy: 0.9810\n",
            "Epoch 00007: val_accuracy did not improve from 0.97052\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 0.0741 - val_accuracy: 0.9705\n",
            "Epoch 8/100\n",
            " 88/109 [=======================>......] - ETA: 0s - loss: 0.0555 - accuracy: 0.9812\n",
            "Epoch 00008: val_accuracy improved from 0.97052 to 0.97279, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0660 - val_accuracy: 0.9728\n",
            "Epoch 9/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9835\n",
            "Epoch 00009: val_accuracy improved from 0.97279 to 0.97959, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0603 - val_accuracy: 0.9796\n",
            "Epoch 10/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9861\n",
            "Epoch 00010: val_accuracy did not improve from 0.97959\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9862 - val_loss: 0.0592 - val_accuracy: 0.9796\n",
            "Epoch 11/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0389 - accuracy: 0.9870\n",
            "Epoch 00011: val_accuracy improved from 0.97959 to 0.98186, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0560 - val_accuracy: 0.9819\n",
            "Epoch 12/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0357 - accuracy: 0.9886\n",
            "Epoch 00012: val_accuracy did not improve from 0.98186\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 0.0596 - val_accuracy: 0.9773\n",
            "Epoch 13/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 0.0322 - accuracy: 0.9900\n",
            "Epoch 00013: val_accuracy did not improve from 0.98186\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0474 - val_accuracy: 0.9773\n",
            "Epoch 14/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0258 - accuracy: 0.9925\n",
            "Epoch 00014: val_accuracy did not improve from 0.98186\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.0455 - val_accuracy: 0.9773\n",
            "Epoch 15/100\n",
            "100/109 [==========================>...] - ETA: 0s - loss: 0.0248 - accuracy: 0.9941\n",
            "Epoch 00015: val_accuracy improved from 0.98186 to 0.98413, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9945 - val_loss: 0.0447 - val_accuracy: 0.9841\n",
            "Epoch 16/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 0.0263 - accuracy: 0.9923\n",
            "Epoch 00016: val_accuracy did not improve from 0.98413\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0433 - val_accuracy: 0.9819\n",
            "Epoch 17/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 0.0217 - accuracy: 0.9940\n",
            "Epoch 00017: val_accuracy did not improve from 0.98413\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.0426 - val_accuracy: 0.9796\n",
            "Epoch 18/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9945\n",
            "Epoch 00018: val_accuracy did not improve from 0.98413\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0418 - val_accuracy: 0.9819\n",
            "Epoch 19/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 0.0168 - accuracy: 0.9964\n",
            "Epoch 00019: val_accuracy did not improve from 0.98413\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0654 - val_accuracy: 0.9683\n",
            "Epoch 20/100\n",
            "102/109 [===========================>..] - ETA: 0s - loss: 0.0162 - accuracy: 0.9954\n",
            "Epoch 00020: val_accuracy improved from 0.98413 to 0.98639, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
            "Epoch 21/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0131 - accuracy: 0.9965\n",
            "Epoch 00021: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0464 - val_accuracy: 0.9819\n",
            "Epoch 22/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971\n",
            "Epoch 00022: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0372 - val_accuracy: 0.9864\n",
            "Epoch 23/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0115 - accuracy: 0.9984\n",
            "Epoch 00023: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0397 - val_accuracy: 0.9864\n",
            "Epoch 24/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9977\n",
            "Epoch 00024: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0385 - val_accuracy: 0.9864\n",
            "Epoch 25/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9980\n",
            "Epoch 00025: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.0372 - val_accuracy: 0.9864\n",
            "Epoch 26/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 0.0093 - accuracy: 0.9976\n",
            "Epoch 00026: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0382 - val_accuracy: 0.9841\n",
            "Epoch 27/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 0.9985\n",
            "Epoch 00027: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0375 - val_accuracy: 0.9841\n",
            "Epoch 28/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9997\n",
            "Epoch 00028: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9864\n",
            "Epoch 29/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0070 - accuracy: 0.9987\n",
            "Epoch 00029: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0365 - val_accuracy: 0.9819\n",
            "Epoch 30/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9988\n",
            "Epoch 00030: val_accuracy did not improve from 0.98639\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0355 - val_accuracy: 0.9841\n",
            "Epoch 31/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
            "Epoch 00031: val_accuracy improved from 0.98639 to 0.99093, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0372 - val_accuracy: 0.9909\n",
            "Epoch 32/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9988\n",
            "Epoch 00032: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0373 - val_accuracy: 0.9819\n",
            "Epoch 33/100\n",
            " 88/109 [=======================>......] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993\n",
            "Epoch 00033: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0389 - val_accuracy: 0.9864\n",
            "Epoch 34/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9887\n",
            "Epoch 35/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 0.0042 - accuracy: 0.9991\n",
            "Epoch 00035: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0379 - val_accuracy: 0.9841\n",
            "Epoch 36/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997\n",
            "Epoch 00036: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9887\n",
            "Epoch 37/100\n",
            "100/109 [==========================>...] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9841\n",
            "Epoch 38/100\n",
            "100/109 [==========================>...] - ETA: 0s - loss: 0.0041 - accuracy: 0.9984\n",
            "Epoch 00038: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0420 - val_accuracy: 0.9841\n",
            "Epoch 39/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 00039: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0395 - val_accuracy: 0.9819\n",
            "Epoch 40/100\n",
            "101/109 [==========================>...] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9841\n",
            "Epoch 41/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 00041: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0394 - val_accuracy: 0.9819\n",
            "Epoch 42/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 00042: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0357 - val_accuracy: 0.9864\n",
            "Epoch 43/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 0.9997\n",
            "Epoch 00043: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0346 - val_accuracy: 0.9819\n",
            "Epoch 44/100\n",
            "101/109 [==========================>...] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 00044: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0387 - val_accuracy: 0.9819\n",
            "Epoch 45/100\n",
            " 99/109 [==========================>...] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9819\n",
            "Epoch 46/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9819\n",
            "Epoch 47/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9796\n",
            "Epoch 48/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9864\n",
            "Epoch 49/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 00049: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9796\n",
            "Epoch 50/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 00050: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0343 - val_accuracy: 0.9841\n",
            "Epoch 51/100\n",
            " 99/109 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 00051: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0366 - val_accuracy: 0.9841\n",
            "Epoch 52/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 6.9821e-04 - accuracy: 1.0000\n",
            "Epoch 00052: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 7.7420e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9819\n",
            "Epoch 53/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 00053: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9819\n",
            "Epoch 54/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 6.6508e-04 - accuracy: 1.0000\n",
            "Epoch 00054: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.6230e-04 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9909\n",
            "Epoch 55/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 5.2453e-04 - accuracy: 1.0000\n",
            "Epoch 00055: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.6334e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9864\n",
            "Epoch 56/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 00056: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0389 - val_accuracy: 0.9819\n",
            "Epoch 57/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 00057: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 9.9880e-04 - accuracy: 0.9997 - val_loss: 0.0395 - val_accuracy: 0.9819\n",
            "Epoch 58/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 5.6269e-04 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.2514e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9841\n",
            "Epoch 59/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 6.0167e-04 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.0167e-04 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9819\n",
            "Epoch 60/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 7.3981e-04 - accuracy: 1.0000\n",
            "Epoch 00060: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.8699e-04 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9887\n",
            "Epoch 61/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 5.1462e-04 - accuracy: 1.0000\n",
            "Epoch 00061: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.9746e-04 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9841\n",
            "Epoch 62/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 5.0514e-04 - accuracy: 1.0000\n",
            "Epoch 00062: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.9960e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9887\n",
            "Epoch 63/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 3.8400e-04 - accuracy: 1.0000\n",
            "Epoch 00063: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.8162e-04 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9841\n",
            "Epoch 64/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 9.0703e-04 - accuracy: 0.9997\n",
            "Epoch 00064: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.4067e-04 - accuracy: 0.9997 - val_loss: 0.0435 - val_accuracy: 0.9841\n",
            "Epoch 65/100\n",
            " 98/109 [=========================>....] - ETA: 0s - loss: 3.6948e-04 - accuracy: 1.0000\n",
            "Epoch 00065: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 3.4565e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9819\n",
            "Epoch 66/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 4.4620e-04 - accuracy: 1.0000\n",
            "Epoch 00066: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 4.9142e-04 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9864\n",
            "Epoch 67/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 2.1072e-04 - accuracy: 1.0000\n",
            "Epoch 00067: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 2.0331e-04 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9841\n",
            "Epoch 68/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 3.5437e-04 - accuracy: 1.0000\n",
            "Epoch 00068: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.5726e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9819\n",
            "Epoch 69/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 2.3099e-04 - accuracy: 1.0000\n",
            "Epoch 00069: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.2276e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9841\n",
            "Epoch 70/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 1.7041e-04 - accuracy: 1.0000\n",
            "Epoch 00070: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 1.5828e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
            "Epoch 71/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 1.2329e-04 - accuracy: 1.0000\n",
            "Epoch 00071: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
            "Epoch 72/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 4.2359e-04 - accuracy: 1.0000\n",
            "Epoch 00072: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.8911e-04 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9864\n",
            "Epoch 73/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 2.6079e-04 - accuracy: 1.0000\n",
            "Epoch 00073: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.6210e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9841\n",
            "Epoch 74/100\n",
            "100/109 [==========================>...] - ETA: 0s - loss: 1.6190e-04 - accuracy: 1.0000\n",
            "Epoch 00074: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.7693e-04 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9887\n",
            "Epoch 75/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 1.5816e-04 - accuracy: 1.0000\n",
            "Epoch 00075: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.5613e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9887\n",
            "Epoch 76/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 1.1790e-04 - accuracy: 1.0000\n",
            "Epoch 00076: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2408e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9864\n",
            "Epoch 77/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 1.6285e-04 - accuracy: 1.0000\n",
            "Epoch 00077: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.5754e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9864\n",
            "Epoch 78/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 3.9815e-04 - accuracy: 1.0000\n",
            "Epoch 00078: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.8542e-04 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9819\n",
            "Epoch 79/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 1.0560e-04 - accuracy: 1.0000\n",
            "Epoch 00079: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0128e-04 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9841\n",
            "Epoch 80/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 2.5507e-04 - accuracy: 1.0000\n",
            "Epoch 00080: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.5385e-04 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
            "Epoch 81/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 7.2310e-05 - accuracy: 1.0000\n",
            "Epoch 00081: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 7.0661e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9864\n",
            "Epoch 82/100\n",
            "102/109 [===========================>..] - ETA: 0s - loss: 7.1270e-05 - accuracy: 1.0000\n",
            "Epoch 00082: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.9803e-05 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9819\n",
            "Epoch 83/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 8.4129e-05 - accuracy: 1.0000\n",
            "Epoch 00083: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.3869e-05 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9887\n",
            "Epoch 84/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 7.7510e-05 - accuracy: 1.0000\n",
            "Epoch 00084: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 7.5934e-05 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9841\n",
            "Epoch 85/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 7.7814e-05 - accuracy: 1.0000\n",
            "Epoch 00085: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.0328e-05 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9909\n",
            "Epoch 86/100\n",
            "102/109 [===========================>..] - ETA: 0s - loss: 4.4048e-05 - accuracy: 1.0000\n",
            "Epoch 00086: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0933e-04 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9864\n",
            "Epoch 87/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 5.5475e-05 - accuracy: 1.0000\n",
            "Epoch 00087: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.3039e-05 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9887\n",
            "Epoch 88/100\n",
            "101/109 [==========================>...] - ETA: 0s - loss: 8.3154e-05 - accuracy: 1.0000\n",
            "Epoch 00088: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.0131e-04 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9864\n",
            "Epoch 89/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 8.0308e-05 - accuracy: 1.0000\n",
            "Epoch 00089: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 7.8779e-05 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
            "Epoch 90/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 1.4196e-04 - accuracy: 1.0000\n",
            "Epoch 00090: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2920e-04 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
            "Epoch 91/100\n",
            "102/109 [===========================>..] - ETA: 0s - loss: 5.1319e-05 - accuracy: 1.0000\n",
            "Epoch 00091: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.0784e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9819\n",
            "Epoch 92/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 5.4342e-05 - accuracy: 1.0000\n",
            "Epoch 00092: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.1557e-05 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9887\n",
            "Epoch 93/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 5.5973e-05 - accuracy: 1.0000\n",
            "Epoch 00093: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.5631e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9864\n",
            "Epoch 94/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 6.4828e-05 - accuracy: 1.0000\n",
            "Epoch 00094: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.2713e-05 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9887\n",
            "Epoch 95/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 3.1497e-05 - accuracy: 1.0000\n",
            "Epoch 00095: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.1061e-05 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9841\n",
            "Epoch 96/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 2.4779e-05 - accuracy: 1.0000\n",
            "Epoch 00096: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.4326e-05 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9864\n",
            "Epoch 97/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 2.6812e-05 - accuracy: 1.0000\n",
            "Epoch 00097: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.4895e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9864\n",
            "Epoch 98/100\n",
            "102/109 [===========================>..] - ETA: 0s - loss: 3.1348e-05 - accuracy: 1.0000\n",
            "Epoch 00098: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.0677e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9887\n",
            "Epoch 99/100\n",
            "100/109 [==========================>...] - ETA: 0s - loss: 5.1390e-05 - accuracy: 1.0000\n",
            "Epoch 00099: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.4045e-05 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9841\n",
            "Epoch 100/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 1.2144e-04 - accuracy: 1.0000\n",
            "Epoch 00100: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1345e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9819\n",
            "Epoch 00100: early stopping\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFN_A1_KTLwD",
        "outputId": "c7833c75-d36a-4161-e915-9357e2ff7370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (12,4))\n",
        " \n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], 'b-', label = 'loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label = 'acc')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label = 'val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdW4m_e-TOEW",
        "outputId": "65f569c3-8f38-41bd-f65a-ddfeb9e7a414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = model.evaluate(valid_features, valid_Y)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9819\n",
            "Test accuracy:  0.9818593859672546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1AmVezyTRMc"
      },
      "source": [
        "model.save('/content/drive/My Drive/efficientnet_audio.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U_sLvTWTXB6",
        "outputId": "eb9ef915-bda9-40ad-d5b8-89a21f7c2b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('i')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}