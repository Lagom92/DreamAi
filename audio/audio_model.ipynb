{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgpKyDzkLEC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAg2--y2IZX8",
        "outputId": "94ed537c-bcf8-4b2e-dbda-38592a9d7764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9DnvZzZIUKQ"
      },
      "source": [
        "#EffcientNet-b4\n",
        "res_url = 'https://tfhub.dev/tensorflow/efficientnet/lite4/classification/2'\n",
        "feature_model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(res_url,trainable=False)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwGlevo_Rq6a",
        "outputId": "f0509658-901e-4c43-e41a-058dd5a4da97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "expect_img_size = 528\n",
        "\n",
        "feature_model.build([None, expect_img_size, expect_img_size, 3])\n",
        "feature_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_3 (KerasLayer)   (None, 1000)              13118936  \n",
            "=================================================================\n",
            "Total params: 13,118,936\n",
            "Trainable params: 0\n",
            "Non-trainable params: 13,118,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwSqhNxuXhU0"
      },
      "source": [
        "feature_model.save('/content/drive/My Drive/efficientnet_feature.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_TL9Z7fIhJD",
        "outputId": "d6a7288e-3019-429e-8b1c-26e4636f78ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "\n",
        "image_size = 528\n",
        "batch_size = 32\n",
        "\n",
        "# 학습 및 검증 데이터용 ImageDataGenerator 생성\n",
        "train_datagen = ImageDataGenerator(rescale=1./255., \n",
        "                                   validation_split = 0.25)\n",
        "\n",
        "#검증데이터\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255., \n",
        "                                   validation_split = 0.25)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = '/content/drive/My Drive/audio_predict/train_image_data',\n",
        "                                                    subset = 'training',   \n",
        "                                                    batch_size = batch_size,\n",
        "                                                    seed = 126,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (image_size,image_size))\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory = '/content/drive/My Drive/audio_predict/train_image_data',\n",
        "                                                    subset = 'validation',\n",
        "                                                    batch_size = 1,\n",
        "                                                    seed = 126,\n",
        "                                                    shuffle = True,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    target_size = (image_size,image_size))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1323 images belonging to 2 classes.\n",
            "Found 441 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd1-mCk37uJ8",
        "outputId": "fdd5aad4-2120-4810-9858-fe01a30aea90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGNN-SPqRwGE",
        "outputId": "e8b2d2b4-eda2-4883-a063-7ba9ee65fcde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 이미지 보강 2배\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "image_size = 500\n",
        "batch_size = 32\n",
        "\n",
        "batch_step = (1764 * 2) // batch_size #데이터 증폭 시켜 배치 스텝구하기\n",
        "train_features = [] \n",
        "train_Y = [] \n",
        "\n",
        "for idx in tqdm(range(batch_step)):\n",
        "  x, y = train_generator.next() #next()를 활용하여 train_generator에 담겨진 [[입력픽셀],[라벨링]] 을 x와 y에 담아 준다.   \n",
        "  train_Y.extend(y) #append()와 비슷한 기능, list에 appending 수행\n",
        "  \n",
        "  # feature_model : 이미 학습이 완료된 특징 추출기 (우리가 불러옴)\n",
        "  # 학습데이터 x 를 활용해서 feature_model을 통과시켜 특징 추출.\n",
        "  feature = feature_model.predict(x)\n",
        "  train_features.extend(feature)\n",
        "\n",
        "#array 전환 \n",
        "train_features = np.array(train_features)\n",
        "train_Y = np.array(train_Y)\n",
        "\n",
        "print(train_features.shape)\n",
        "print(train_Y.shape)\n",
        "print(train_Y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [06:42<00:00,  3.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3478, 1000)\n",
            "(3478, 2)\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2SFrfzcSIlq",
        "outputId": "85e1dec9-2fc7-4756-d8b0-854ac3ba0227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_features = [] \n",
        "valid_Y = [] \n",
        "\n",
        "for idx in tqdm(range(valid_generator.n)):\n",
        "  x, y = valid_generator.next() #next()를 활용하여 valid_generator에 담겨진 [[입력픽셀],[라벨링]] 을 x와 y에 담아 준다.   \n",
        "  valid_Y.extend(y) #append()와 비슷한 기능, list에 appending 수행\n",
        "  \n",
        "  # feature_model : 이미 학습이 완료된 특징 추출기 (우리가 불러옴)\n",
        "  # 학습데이터 x 를 활용해서 feature_model을 통과시켜 특징 추출.\n",
        "  feature = feature_model.predict(x)\n",
        "  valid_features.extend(feature)\n",
        "\n",
        "#array 전환 \n",
        "valid_features = np.array(valid_features)\n",
        "valid_Y = np.array(valid_Y)\n",
        "\n",
        "print(valid_features.shape)\n",
        "print(valid_Y.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 441/441 [02:22<00:00,  3.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(441, 1000)\n",
            "(441, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJjKJFL4Iihx",
        "outputId": "a2435e28-3abf-4bdb-9ebd-d0493b8115df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(256, activation= 'relu', input_shape = (1000,)),\n",
        "                             tf.keras.layers.Dropout(0.5),\n",
        "                             tf.keras.layers.Dense(2,activation='softmax')\n",
        "])\n",
        "model.compile(tf.optimizers.RMSprop(0.0001), \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EgXhczHSpwo",
        "outputId": "ad28b834-6f05-422b-fb9c-10b68ccfc70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint_path = '/content/drive/My Drive/check.h5'\n",
        "\n",
        "cp = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                save_weights_only=True,\n",
        "                                save_best_only=True,\n",
        "                                monitor='val_accuracy',\n",
        "                                verbose=1)\n",
        "\n",
        "es = EarlyStopping(patience=50, verbose=1)\n",
        "history = model.fit(train_features, train_Y, \n",
        "                    validation_data=(valid_features, valid_Y),\n",
        "                    epochs = 100,\n",
        "                    batch_size = 32,\n",
        "                    callbacks=[es,cp])\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 0.2872 - accuracy: 0.8794\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.96372, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.8899 - val_loss: 0.1215 - val_accuracy: 0.9637\n",
            "Epoch 2/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9611\n",
            "Epoch 00002: val_accuracy improved from 0.96372 to 0.97052, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9623 - val_loss: 0.0918 - val_accuracy: 0.9705\n",
            "Epoch 3/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0709 - accuracy: 0.9754\n",
            "Epoch 00003: val_accuracy improved from 0.97052 to 0.97732, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9747 - val_loss: 0.0748 - val_accuracy: 0.9773\n",
            "Epoch 4/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0559 - accuracy: 0.9817\n",
            "Epoch 00004: val_accuracy improved from 0.97732 to 0.98866, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.0579 - val_accuracy: 0.9887\n",
            "Epoch 5/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 0.0409 - accuracy: 0.9862\n",
            "Epoch 00005: val_accuracy improved from 0.98866 to 0.99093, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.0465 - val_accuracy: 0.9909\n",
            "Epoch 6/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9883\n",
            "Epoch 00006: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.0495 - val_accuracy: 0.9841\n",
            "Epoch 7/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9905\n",
            "Epoch 00007: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.0359 - val_accuracy: 0.9909\n",
            "Epoch 8/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0241 - accuracy: 0.9925\n",
            "Epoch 00008: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0375 - val_accuracy: 0.9909\n",
            "Epoch 9/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 0.0210 - accuracy: 0.9940\n",
            "Epoch 00009: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0368 - val_accuracy: 0.9887\n",
            "Epoch 10/100\n",
            " 98/109 [=========================>....] - ETA: 0s - loss: 0.0197 - accuracy: 0.9946\n",
            "Epoch 00010: val_accuracy did not improve from 0.99093\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0282 - val_accuracy: 0.9909\n",
            "Epoch 11/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 0.0149 - accuracy: 0.9966\n",
            "Epoch 00011: val_accuracy improved from 0.99093 to 0.99320, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.0233 - val_accuracy: 0.9932\n",
            "Epoch 12/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0142 - accuracy: 0.9967\n",
            "Epoch 00012: val_accuracy did not improve from 0.99320\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0255 - val_accuracy: 0.9909\n",
            "Epoch 13/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967\n",
            "Epoch 00013: val_accuracy improved from 0.99320 to 0.99546, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.0207 - val_accuracy: 0.9955\n",
            "Epoch 14/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 0.0108 - accuracy: 0.9980\n",
            "Epoch 00014: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0221 - val_accuracy: 0.9909\n",
            "Epoch 15/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 0.0106 - accuracy: 0.9973\n",
            "Epoch 00015: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0253 - val_accuracy: 0.9909\n",
            "Epoch 16/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9977\n",
            "Epoch 00016: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0235 - val_accuracy: 0.9909\n",
            "Epoch 17/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993\n",
            "Epoch 00017: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0174 - val_accuracy: 0.9955\n",
            "Epoch 18/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
            "Epoch 00018: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0214 - val_accuracy: 0.9909\n",
            "Epoch 19/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
            "Epoch 00019: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
            "Epoch 20/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993\n",
            "Epoch 00020: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
            "Epoch 21/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 0.0042 - accuracy: 0.9997\n",
            "Epoch 00021: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0214 - val_accuracy: 0.9909\n",
            "Epoch 22/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0059 - accuracy: 0.9977\n",
            "Epoch 00022: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0157 - val_accuracy: 0.9955\n",
            "Epoch 23/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 00023: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9955\n",
            "Epoch 24/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
            "Epoch 00024: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
            "Epoch 25/100\n",
            " 99/109 [==========================>...] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 00025: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9909\n",
            "Epoch 26/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 00026: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0161 - val_accuracy: 0.9955\n",
            "Epoch 27/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 00027: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
            "Epoch 28/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 00028: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9887\n",
            "Epoch 29/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
            "Epoch 00029: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.0314 - val_accuracy: 0.9887\n",
            "Epoch 30/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 00030: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9955\n",
            "Epoch 31/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9955\n",
            "Epoch 32/100\n",
            "101/109 [==========================>...] - ETA: 0s - loss: 9.6666e-04 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 9.8048e-04 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9955\n",
            "Epoch 33/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 00033: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9955\n",
            "Epoch 34/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997    \n",
            "Epoch 00034: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0222 - val_accuracy: 0.9909\n",
            "Epoch 35/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 00035: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0139 - val_accuracy: 0.9955\n",
            "Epoch 36/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00036: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9955\n",
            "Epoch 37/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 7.6147e-04 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.8937e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9955\n",
            "Epoch 38/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 6.8423e-04 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.1527e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9955\n",
            "Epoch 39/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
            "Epoch 00039: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0112 - val_accuracy: 0.9955\n",
            "Epoch 40/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 4.1176e-04 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.0577e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9955\n",
            "Epoch 41/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 7.8387e-04 - accuracy: 0.9997\n",
            "Epoch 00041: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.1906e-04 - accuracy: 0.9997 - val_loss: 0.0269 - val_accuracy: 0.9887\n",
            "Epoch 42/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 5.7609e-04 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.3431e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9955\n",
            "Epoch 43/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 5.6586e-04 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.2518e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9955\n",
            "Epoch 44/100\n",
            " 90/109 [=======================>......] - ETA: 0s - loss: 5.9402e-04 - accuracy: 1.0000\n",
            "Epoch 00044: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.8963e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9955\n",
            "Epoch 45/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 3.3527e-04 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.0720e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9955\n",
            "Epoch 46/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 3.0957e-04 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.2856e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9955\n",
            "Epoch 47/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 3.3448e-04 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.4501e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9955\n",
            "Epoch 48/100\n",
            " 99/109 [==========================>...] - ETA: 0s - loss: 7.7927e-04 - accuracy: 0.9997\n",
            "Epoch 00048: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 7.2081e-04 - accuracy: 0.9997 - val_loss: 0.0214 - val_accuracy: 0.9932\n",
            "Epoch 49/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 3.7384e-04 - accuracy: 0.9997\n",
            "Epoch 00049: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.6758e-04 - accuracy: 0.9997 - val_loss: 0.0104 - val_accuracy: 0.9955\n",
            "Epoch 50/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 2.2927e-04 - accuracy: 1.0000\n",
            "Epoch 00050: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.1840e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9955\n",
            "Epoch 51/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 2.7343e-04 - accuracy: 1.0000\n",
            "Epoch 00051: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.4934e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9955\n",
            "Epoch 52/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 2.8133e-04 - accuracy: 1.0000\n",
            "Epoch 00052: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.5665e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9955\n",
            "Epoch 53/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 1.6515e-04 - accuracy: 1.0000\n",
            "Epoch 00053: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.6445e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9955\n",
            "Epoch 54/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 2.8706e-04 - accuracy: 1.0000\n",
            "Epoch 00054: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.5747e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9955\n",
            "Epoch 55/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 3.5110e-04 - accuracy: 1.0000\n",
            "Epoch 00055: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.4900e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9955\n",
            "Epoch 56/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.7173e-04 - accuracy: 1.0000\n",
            "Epoch 00056: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.7173e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
            "Epoch 57/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.3066e-04 - accuracy: 1.0000\n",
            "Epoch 00057: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.3066e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9955\n",
            "Epoch 58/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 1.2098e-04 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2258e-04 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9955\n",
            "Epoch 59/100\n",
            " 98/109 [=========================>....] - ETA: 0s - loss: 1.3418e-04 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2482e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9955\n",
            "Epoch 60/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 4.5194e-05 - accuracy: 1.0000\n",
            "Epoch 00060: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.8617e-05 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9955\n",
            "Epoch 61/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 7.8643e-05 - accuracy: 1.0000\n",
            "Epoch 00061: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 7.6099e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
            "Epoch 62/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 5.7083e-05 - accuracy: 1.0000\n",
            "Epoch 00062: val_accuracy did not improve from 0.99546\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.9225e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9955\n",
            "Epoch 63/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 4.7486e-05 - accuracy: 1.0000\n",
            "Epoch 00063: val_accuracy improved from 0.99546 to 0.99773, saving model to /content/drive/My Drive/check.h5\n",
            "109/109 [==============================] - 1s 5ms/step - loss: 4.7486e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9977\n",
            "Epoch 64/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 5.3387e-05 - accuracy: 1.0000\n",
            "Epoch 00064: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 8.3405e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
            "Epoch 65/100\n",
            " 93/109 [========================>.....] - ETA: 0s - loss: 1.8522e-04 - accuracy: 1.0000\n",
            "Epoch 00065: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.6456e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9955\n",
            "Epoch 66/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 3.9850e-05 - accuracy: 1.0000\n",
            "Epoch 00066: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.6101e-05 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
            "Epoch 67/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 5.7749e-05 - accuracy: 1.0000\n",
            "Epoch 00067: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.7749e-05 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9955\n",
            "Epoch 68/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 6.3758e-05 - accuracy: 1.0000\n",
            "Epoch 00068: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.7267e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9955\n",
            "Epoch 69/100\n",
            " 99/109 [==========================>...] - ETA: 0s - loss: 5.7760e-05 - accuracy: 1.0000\n",
            "Epoch 00069: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.4423e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9955\n",
            "Epoch 70/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 4.4298e-05 - accuracy: 1.0000\n",
            "Epoch 00070: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.0211e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9955\n",
            "Epoch 71/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 1.1201e-04 - accuracy: 1.0000\n",
            "Epoch 00071: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1201e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9955\n",
            "Epoch 72/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 2.8979e-05 - accuracy: 1.0000\n",
            "Epoch 00072: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.8812e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9955\n",
            "Epoch 73/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 2.3593e-05 - accuracy: 1.0000\n",
            "Epoch 00073: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.2993e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9955\n",
            "Epoch 74/100\n",
            " 97/109 [=========================>....] - ETA: 0s - loss: 4.8807e-05 - accuracy: 1.0000\n",
            "Epoch 00074: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.5315e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9955\n",
            "Epoch 75/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.9835e-05 - accuracy: 1.0000\n",
            "Epoch 00075: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.9835e-05 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9955\n",
            "Epoch 76/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 1.7401e-05 - accuracy: 1.0000\n",
            "Epoch 00076: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.1322e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9955\n",
            "Epoch 77/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 8.2773e-06 - accuracy: 1.0000\n",
            "Epoch 00077: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2997e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9955\n",
            "Epoch 78/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 1.3303e-05 - accuracy: 1.0000\n",
            "Epoch 00078: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.3011e-05 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9955\n",
            "Epoch 79/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.1159e-05 - accuracy: 1.0000\n",
            "Epoch 00079: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.1159e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9955\n",
            "Epoch 80/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 6.0797e-05 - accuracy: 1.0000\n",
            "Epoch 00080: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.0413e-05 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
            "Epoch 81/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 1.2005e-05 - accuracy: 1.0000\n",
            "Epoch 00081: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1665e-05 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9955\n",
            "Epoch 82/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 1.8711e-05 - accuracy: 1.0000\n",
            "Epoch 00082: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.8433e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9955\n",
            "Epoch 83/100\n",
            " 96/109 [=========================>....] - ETA: 0s - loss: 2.2625e-05 - accuracy: 1.0000\n",
            "Epoch 00083: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.0908e-05 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9977\n",
            "Epoch 84/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 1.2899e-05 - accuracy: 1.0000\n",
            "Epoch 00084: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.2331e-05 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
            "Epoch 85/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 1.3757e-05 - accuracy: 1.0000\n",
            "Epoch 00085: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.3670e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9955\n",
            "Epoch 86/100\n",
            " 94/109 [========================>.....] - ETA: 0s - loss: 7.4258e-06 - accuracy: 1.0000\n",
            "Epoch 00086: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.8536e-06 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9955\n",
            "Epoch 87/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 5.9218e-06 - accuracy: 1.0000\n",
            "Epoch 00087: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.9218e-06 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9955\n",
            "Epoch 88/100\n",
            " 92/109 [========================>.....] - ETA: 0s - loss: 7.2186e-06 - accuracy: 1.0000\n",
            "Epoch 00088: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.3966e-06 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9955\n",
            "Epoch 89/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 2.2237e-05 - accuracy: 1.0000\n",
            "Epoch 00089: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.5305e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9932\n",
            "Epoch 90/100\n",
            "107/109 [============================>.] - ETA: 0s - loss: 5.6848e-06 - accuracy: 1.0000\n",
            "Epoch 00090: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.5970e-06 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9955\n",
            "Epoch 91/100\n",
            " 95/109 [=========================>....] - ETA: 0s - loss: 3.2892e-06 - accuracy: 1.0000\n",
            "Epoch 00091: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 3.2984e-06 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9955\n",
            "Epoch 92/100\n",
            "103/109 [===========================>..] - ETA: 0s - loss: 4.8164e-06 - accuracy: 1.0000\n",
            "Epoch 00092: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.7650e-06 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9955\n",
            "Epoch 93/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 1.1070e-05 - accuracy: 1.0000\n",
            "Epoch 00093: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.1000e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9932\n",
            "Epoch 94/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 5.1924e-06 - accuracy: 1.0000\n",
            "Epoch 00094: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 5.1596e-06 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
            "Epoch 95/100\n",
            "106/109 [============================>.] - ETA: 0s - loss: 1.8356e-05 - accuracy: 1.0000\n",
            "Epoch 00095: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.8039e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
            "Epoch 96/100\n",
            "108/109 [============================>.] - ETA: 0s - loss: 4.6589e-06 - accuracy: 1.0000\n",
            "Epoch 00096: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 4.6295e-06 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9977\n",
            "Epoch 97/100\n",
            " 91/109 [========================>.....] - ETA: 0s - loss: 2.4204e-06 - accuracy: 1.0000\n",
            "Epoch 00097: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.2590e-06 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9955\n",
            "Epoch 98/100\n",
            "105/109 [===========================>..] - ETA: 0s - loss: 6.5886e-06 - accuracy: 1.0000\n",
            "Epoch 00098: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 6.4422e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9977\n",
            "Epoch 99/100\n",
            "109/109 [==============================] - ETA: 0s - loss: 2.4062e-06 - accuracy: 1.0000\n",
            "Epoch 00099: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 2.4062e-06 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9955\n",
            "Epoch 100/100\n",
            "104/109 [===========================>..] - ETA: 0s - loss: 1.9626e-06 - accuracy: 1.0000\n",
            "Epoch 00100: val_accuracy did not improve from 0.99773\n",
            "109/109 [==============================] - 0s 3ms/step - loss: 1.8842e-06 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9955\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFN_A1_KTLwD",
        "outputId": "7568578b-52c3-4661-ab8b-c52bdc9ee804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (12,4))\n",
        " \n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], 'b-', label = 'loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label = 'acc')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label = 'val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdW4m_e-TOEW",
        "outputId": "f6498b7b-13eb-48bf-af54-1415297a85c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = model.evaluate(valid_features, valid_Y)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9955\n",
            "Test accuracy:  0.9954648613929749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1AmVezyTRMc"
      },
      "source": [
        "model.save('/content/drive/My Drive/efficientnet_audio_500.h5')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U_sLvTWTXB6",
        "outputId": "eb9ef915-bda9-40ad-d5b8-89a21f7c2b5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('i')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}