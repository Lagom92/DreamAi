{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import mudules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input ImageDataGenerator (audio : Mel-spectrogram / image : cropped CXR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5730 images belonging to 2 classes.\n",
      "Found 5730 images belonging to 2 classes.\n",
      "5730\n",
      "5730\n"
     ]
    }
   ],
   "source": [
    "image_path = '../image_data/cropped_train/'\n",
    "audio_path = '../audio_data/train_Mel/'\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "\n",
    "generator_tra1 = train_datagen.flow_from_directory(\n",
    "                                    directory=image_path,\n",
    "                                    subset = 'training',\n",
    "                                    target_size = (image_size,image_size),\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 126)\n",
    "\n",
    "generator_tra2 = train_datagen.flow_from_directory(\n",
    "                                    directory=audio_path,\n",
    "                                    subset = 'training',\n",
    "                                    target_size = (image_size,image_size),\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 126)\n",
    "\n",
    "print(generator_tra1.n)\n",
    "print(generator_tra2.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1431 images belonging to 2 classes.\n",
      "Found 1431 images belonging to 2 classes.\n",
      "1431\n",
      "1431\n"
     ]
    }
   ],
   "source": [
    "generator_val1 = train_datagen.flow_from_directory(\n",
    "                                    directory=image_path,\n",
    "                                    subset = 'validation',\n",
    "                                    target_size = (image_size,image_size),\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 126)\n",
    "\n",
    "generator_val2 = train_datagen.flow_from_directory(\n",
    "                                    directory=audio_path,\n",
    "                                    subset = 'validation',\n",
    "                                    target_size = (image_size,image_size),\n",
    "                                    color_mode = 'rgb',\n",
    "                                    class_mode = 'binary',\n",
    "                                    batch_size = batch_size,\n",
    "                                    shuffle = True,\n",
    "                                    seed = 126)\n",
    "\n",
    "print(generator_val1.n)\n",
    "print(generator_val2.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos, neg 데이터의 수를 맞춰야 같은 라벨을 가져올 수 있다.\n",
    "def two_image_generator(gen1, gen2):\n",
    "\n",
    "    while True:\n",
    "        CXR, Y = gen1.next()\n",
    "        Audio, Y = gen2.next()\n",
    "\n",
    "        yield [CXR,Audio], Y  #X1i[1] is the label\n",
    "\n",
    "train_generator = two_image_generator(generator_tra1,generator_tra2)\n",
    "valid_generator = two_image_generator(generator_val1,generator_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = tf.keras.applications.DenseNet201(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(image_size,image_size,3),\n",
    ")\n",
    "\n",
    "# feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  707\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet201 (Functional)        (None, 7, 7, 1920)   18321984    input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            2630657     densenet201[0][0]                \n",
      "                                                                 densenet201[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,952,641\n",
      "Trainable params: 15,368,769\n",
      "Non-trainable params: 5,583,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # 미세 조정을 하려면 처음부터 freezing을 풀어 놓아도 된다.\n",
    "# feature_model.trainable = True\n",
    "\n",
    "# print(\"Number of layers in the base model: \", len(feature_model.layers))\n",
    "# fine_tune_at = 350\n",
    "\n",
    "# for layer in feature_model.layers[:fine_tune_at]:\n",
    "#     layer.trainable =  False\n",
    "\n",
    "# finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "densenet201 (Functional)     (None, 7, 7, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1920)              0         \n",
      "=================================================================\n",
      "Total params: 18,321,984\n",
      "Trainable params: 14,028,480\n",
      "Non-trainable params: 4,293,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터가 매우 많을 때는 featrue model 하단에 GAP레이어를 쌓아서 \n",
    "# numpy array로 저장되는 데이터의 수를 줄여준다.\n",
    "\n",
    "# def build_feature_model(feature_model):\n",
    "#     inputs = Input(shape=(image_size,image_size,3))\n",
    "#     x = feature_model(inputs)\n",
    "#     outputs = GlobalAveragePooling2D()(x)\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# feature_model_GAP = build_feature_model(feature_model)\n",
    "# feature_model_GAP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [01:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5728, 7, 7, 1920)\n",
      "(5728, 7, 7, 1920)\n",
      "(5728,)\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "train_img_features = []\n",
    "train_aud_features = []\n",
    "\n",
    "for i in tqdm(range(generator_tra1.n//batch_size)):\n",
    "    \n",
    "    [x1, x2] , y = train_generator.__next__()\n",
    "    \n",
    "    train_labels.extend(y)\n",
    "    \n",
    "    feature1, feature2 = feature_model.predict(x1), feature_model.predict(x2)\n",
    "    train_img_features.extend(feature1)\n",
    "    train_aud_features.extend(feature2)\n",
    "    \n",
    "train_img_features = np.array(train_img_features)\n",
    "train_aud_features = np.array(train_aud_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(train_img_features.shape)\n",
    "print(train_aud_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:16<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 7, 7, 1920)\n",
      "(1408, 7, 7, 1920)\n",
      "(1408,)\n"
     ]
    }
   ],
   "source": [
    "# train 데이터는 수가 너무많음 따라서 이방법은 train데이터에는 사용 X\n",
    "valid_labels = []\n",
    "valid_img_features = []\n",
    "valid_aud_features = []\n",
    "\n",
    "for i in tqdm(range(generator_val1.n//batch_size)):\n",
    "    \n",
    "    [x1, x2] , y = valid_generator.__next__()\n",
    "    valid_labels.extend(y)\n",
    "    feature1, feature2 = feature_model.predict(x1), feature_model.predict(x2)\n",
    "    valid_img_features.extend(feature1)\n",
    "    valid_aud_features.extend(feature2)\n",
    "    \n",
    "valid_img_features = np.array(valid_img_features)\n",
    "valid_aud_features = np.array(valid_aud_features)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "print(valid_img_features.shape)\n",
    "print(valid_aud_features.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'mulit-input_features/train_img.npy'\n",
    "train_aud_path =  'mulit-input_features/train_aud.npy'\n",
    "train_labels_path =  'mulit-input_features/train_labels.npy'\n",
    "\n",
    "valid_img_path = 'mulit-input_features/valid_img.npy'\n",
    "valid_aud_path =  'mulit-input_features/valid_aud.npy'\n",
    "valid_labels_path =  'mulit-input_features/valid_labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(train_img_path, train_img_features)\n",
    "np.save(train_aud_path, train_aud_features)\n",
    "np.save(train_labels_path, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(valid_img_path, valid_img_features)\n",
    "np.save(valid_aud_path, valid_aud_features)\n",
    "np.save(valid_labels_path, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_features = np.load(train_img_path)\n",
    "# train_aud_features  = np.load(train_aud_path)\n",
    "# train_labels = np.load(train_labels_path)\n",
    "\n",
    "# valid_img_features = np.load(valid_img_path)\n",
    "# valid_aud_features = np.load(valid_aud_path)\n",
    "# valid_labels = np.load(valid_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    inputs1 = Input(shape=feature_model.output.shape[1:])\n",
    "    inputs2 = Input(shape=feature_model.output.shape[1:])\n",
    "\n",
    "    merged = Concatenate(axis=1)([inputs1, inputs2])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(merged)\n",
    "\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2],\n",
    "                 outputs = outputs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=4e-4),\n",
    "                  loss= 'binary_crossentropy',\n",
    "                  metrics='accuracy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 7, 7, 1920)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 7, 7, 1920)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 7, 1920)  0           input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1920)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1967104     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            257         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,630,657\n",
      "Trainable params: 2,627,073\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구축\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"testmodel/multi_model.h5\"\n",
    "\n",
    "cp = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1,\n",
    "                        save_best_only=True, save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=5, \n",
    "                                   min_lr=1e-6)\n",
    "es = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=30)\n",
    "callbacks_list = [cp, es, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7802\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.90838, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5406 - accuracy: 0.7819 - val_loss: 0.3243 - val_accuracy: 0.9084\n",
      "Epoch 2/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9122\n",
      "Epoch 00002: val_accuracy improved from 0.90838 to 0.94460, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.2621 - accuracy: 0.9124 - val_loss: 0.1845 - val_accuracy: 0.9446\n",
      "Epoch 3/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9408\n",
      "Epoch 00003: val_accuracy improved from 0.94460 to 0.95170, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.1860 - accuracy: 0.9412 - val_loss: 0.1553 - val_accuracy: 0.9517\n",
      "Epoch 4/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9472\n",
      "Epoch 00004: val_accuracy did not improve from 0.95170\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.1607 - accuracy: 0.9473 - val_loss: 0.1593 - val_accuracy: 0.9496\n",
      "Epoch 5/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9552\n",
      "Epoch 00005: val_accuracy did not improve from 0.95170\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.1425 - accuracy: 0.9546 - val_loss: 0.1451 - val_accuracy: 0.9517\n",
      "Epoch 6/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9544\n",
      "Epoch 00006: val_accuracy did not improve from 0.95170\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.1323 - accuracy: 0.9543 - val_loss: 0.1824 - val_accuracy: 0.9304\n",
      "Epoch 7/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9621\n",
      "Epoch 00007: val_accuracy improved from 0.95170 to 0.95952, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.1123 - accuracy: 0.9612 - val_loss: 0.1163 - val_accuracy: 0.9595\n",
      "Epoch 8/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9672\n",
      "Epoch 00008: val_accuracy did not improve from 0.95952\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0992 - accuracy: 0.9663 - val_loss: 0.1157 - val_accuracy: 0.9567\n",
      "Epoch 9/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9704\n",
      "Epoch 00009: val_accuracy did not improve from 0.95952\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0912 - accuracy: 0.9700 - val_loss: 0.1306 - val_accuracy: 0.9496\n",
      "Epoch 10/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9688\n",
      "Epoch 00010: val_accuracy did not improve from 0.95952\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0844 - accuracy: 0.9688 - val_loss: 0.1184 - val_accuracy: 0.9574\n",
      "Epoch 11/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9659\n",
      "Epoch 00011: val_accuracy improved from 0.95952 to 0.96023, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0973 - accuracy: 0.9661 - val_loss: 0.1169 - val_accuracy: 0.9602\n",
      "Epoch 12/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9682\n",
      "Epoch 00012: val_accuracy improved from 0.96023 to 0.96094, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0845 - accuracy: 0.9684 - val_loss: 0.1214 - val_accuracy: 0.9609\n",
      "Epoch 13/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9733\n",
      "Epoch 00013: val_accuracy did not improve from 0.96094\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0795 - accuracy: 0.9733 - val_loss: 0.1242 - val_accuracy: 0.9503\n",
      "Epoch 14/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9745\n",
      "Epoch 00014: val_accuracy did not improve from 0.96094\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0678 - accuracy: 0.9742 - val_loss: 0.1044 - val_accuracy: 0.9588\n",
      "Epoch 15/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9784\n",
      "Epoch 00015: val_accuracy did not improve from 0.96094\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0556 - accuracy: 0.9787 - val_loss: 0.1097 - val_accuracy: 0.9574\n",
      "Epoch 16/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9795\n",
      "Epoch 00016: val_accuracy did not improve from 0.96094\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.1135 - val_accuracy: 0.9574\n",
      "Epoch 17/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9815\n",
      "Epoch 00017: val_accuracy improved from 0.96094 to 0.96662, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.0931 - val_accuracy: 0.9666\n",
      "Epoch 18/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9793\n",
      "Epoch 00018: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0536 - accuracy: 0.9792 - val_loss: 0.0937 - val_accuracy: 0.9652\n",
      "Epoch 19/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9838\n",
      "Epoch 00019: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0440 - accuracy: 0.9838 - val_loss: 0.0970 - val_accuracy: 0.9624\n",
      "Epoch 20/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9839\n",
      "Epoch 00020: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.1134 - val_accuracy: 0.9553\n",
      "Epoch 21/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9847\n",
      "Epoch 00021: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 0.1075 - val_accuracy: 0.9638\n",
      "Epoch 22/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9848\n",
      "Epoch 00022: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 0.1014 - val_accuracy: 0.9652\n",
      "Epoch 23/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9867\n",
      "Epoch 00023: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.0944 - val_accuracy: 0.9659\n",
      "Epoch 24/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9870\n",
      "Epoch 00024: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.0976 - val_accuracy: 0.9624\n",
      "Epoch 25/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9857\n",
      "Epoch 00025: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0384 - accuracy: 0.9852 - val_loss: 0.0955 - val_accuracy: 0.9659\n",
      "Epoch 26/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9852\n",
      "Epoch 00026: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.1036 - val_accuracy: 0.9624\n",
      "Epoch 27/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9883\n",
      "Epoch 00027: val_accuracy did not improve from 0.96662\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 0.0997 - val_accuracy: 0.9652\n",
      "Epoch 28/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9898\n",
      "Epoch 00028: val_accuracy improved from 0.96662 to 0.96733, saving model to testmodel/multi_model.h5\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.1039 - val_accuracy: 0.9673\n",
      "Epoch 29/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9909\n",
      "Epoch 00029: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.1027 - val_accuracy: 0.9638\n",
      "Epoch 30/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9900\n",
      "Epoch 00030: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.0991 - val_accuracy: 0.9659\n",
      "Epoch 31/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9933\n",
      "Epoch 00031: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.1015 - val_accuracy: 0.9638\n",
      "Epoch 32/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9905\n",
      "Epoch 00032: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.1010 - val_accuracy: 0.9645\n",
      "Epoch 33/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 00033: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0999 - val_accuracy: 0.9638\n",
      "Epoch 34/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9898\n",
      "Epoch 00034: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.1041 - val_accuracy: 0.9624\n",
      "Epoch 35/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9925\n",
      "Epoch 00035: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.1002 - val_accuracy: 0.9631\n",
      "Epoch 36/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9911\n",
      "Epoch 00036: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0985 - val_accuracy: 0.9666\n",
      "Epoch 37/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9911\n",
      "Epoch 00037: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0971 - val_accuracy: 0.9652\n",
      "Epoch 38/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9913\n",
      "Epoch 00038: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0999 - val_accuracy: 0.9652\n",
      "Epoch 39/100\n",
      "176/179 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9911\n",
      "Epoch 00039: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.1012 - val_accuracy: 0.9631\n",
      "Epoch 40/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9879\n",
      "Epoch 00040: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0304 - accuracy: 0.9880 - val_loss: 0.0990 - val_accuracy: 0.9645\n",
      "Epoch 41/100\n",
      "178/179 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9907\n",
      "Epoch 00041: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0257 - accuracy: 0.9907 - val_loss: 0.0983 - val_accuracy: 0.9652\n",
      "Epoch 42/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9914\n",
      "Epoch 00042: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.1008 - val_accuracy: 0.9638\n",
      "Epoch 43/100\n",
      "174/179 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9928\n",
      "Epoch 00043: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 13ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.1002 - val_accuracy: 0.9638\n",
      "Epoch 44/100\n",
      "175/179 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9911\n",
      "Epoch 00044: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.1004 - val_accuracy: 0.9638\n",
      "Epoch 45/100\n",
      "177/179 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9906\n",
      "Epoch 00045: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 0.1005 - val_accuracy: 0.9645\n",
      "Epoch 46/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9921\n",
      "Epoch 00046: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0998 - val_accuracy: 0.9645\n",
      "Epoch 47/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 00047: val_accuracy did not improve from 0.96733\n",
      "179/179 [==============================] - 2s 12ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0999 - val_accuracy: 0.9638\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 7, 7, 1920)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 7, 7, 1920)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 7, 1920)  0           input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1920)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1967104     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            257         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,630,657\n",
      "Trainable params: 2,627,073\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 100\n",
    "\n",
    "history = model.fit(x = [train_img_features, train_aud_features],\n",
    "                    y = train_labels,\n",
    "                    validation_data = ([valid_img_features, valid_aud_features], valid_labels),\n",
    "                    epochs = initial_epochs,\n",
    "                    steps_per_epoch = generator_tra1.n//batch_size,\n",
    "                    validation_steps = generator_val1.n//batch_size,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks = callbacks_list\n",
    "                    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.2])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('Multi_model_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1039 - accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10391395539045334, 0.9673295617103577]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "# 가중치 로드\n",
    "model2.load_weights(weight_path)\n",
    "\n",
    "# 모델 평가\n",
    "model2.evaluate([valid_img_features,valid_aud_features],valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: testmodel/multi_model/assets\n"
     ]
    }
   ],
   "source": [
    "model2.save('testmodel/multi_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파인튜닝은 시간상 하지 않았다. 또한 오디오 데이터가 잘 정제된 것이 아니라서 큰 의미는 없을 것 같았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetuning(model, num_outputs=1):\n",
    "    \n",
    "    inputs1 = Input(shape=(image_size, image_size,3))\n",
    "    inputs2 = Input(shape=(image_size, image_size,3))\n",
    "    \n",
    "    x1 = feature_model(inputs1)\n",
    "    x2 = feature_model(inputs2)\n",
    "    \n",
    "    outputs = model([x1,x2])\n",
    "\n",
    "    model_fine = Model(inputs=[inputs1,inputs2],\n",
    "                 outputs = outputs)\n",
    "    init_lr = 2e-6\n",
    "    opt = Adam(lr=init_lr)\n",
    "    model_fine.compile(optimizer=opt, \n",
    "                    loss= 'binary_crossentropy',\n",
    "                    metrics='accuracy')\n",
    "        \n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "densenet201 (Functional)        (None, 7, 7, 1920)   18321984    input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "functional_7 (Functional)       (None, 1)            2630657     densenet201[2][0]                \n",
      "                                                                 densenet201[3][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,952,641\n",
      "Trainable params: 15,368,769\n",
      "Non-trainable params: 5,583,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finetune = build_finetuning(model2)\n",
    "finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"testmodel/best_multi_finetuned.h5\"\n",
    "\n",
    "cp = ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   min_lr=1e-7)\n",
    "es = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) \n",
    "callbacks_list = [cp, es, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8963\n",
      "Epoch 00047: val_accuracy improved from -inf to 0.92352, saving model to testmodel/best_multi_finetuned.h5\n",
      "179/179 [==============================] - 68s 382ms/step - loss: 0.4150 - accuracy: 0.8963 - val_loss: 0.2966 - val_accuracy: 0.9235\n",
      "Epoch 48/150\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9342\n",
      "Epoch 00048: val_accuracy improved from 0.92352 to 0.92566, saving model to testmodel/best_multi_finetuned.h5\n",
      "179/179 [==============================] - 56s 313ms/step - loss: 0.2200 - accuracy: 0.9342 - val_loss: 0.3032 - val_accuracy: 0.9257\n",
      "Epoch 49/150\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.9479\n",
      "Epoch 00049: val_accuracy did not improve from 0.92566\n",
      "179/179 [==============================] - 55s 309ms/step - loss: 0.1669 - accuracy: 0.9479 - val_loss: 0.2970 - val_accuracy: 0.9249\n",
      "Epoch 50/150\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9607\n",
      "Epoch 00050: val_accuracy improved from 0.92566 to 0.92924, saving model to testmodel/best_multi_finetuned.h5\n",
      "179/179 [==============================] - 56s 312ms/step - loss: 0.1243 - accuracy: 0.9607 - val_loss: 0.2727 - val_accuracy: 0.9292\n",
      "Epoch 51/150\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9679\n",
      "Epoch 00051: val_accuracy did not improve from 0.92924\n",
      "179/179 [==============================] - 55s 306ms/step - loss: 0.1013 - accuracy: 0.9679 - val_loss: 0.2680 - val_accuracy: 0.9278\n",
      "Epoch 52/150\n",
      "142/179 [======================>.......] - ETA: 9s - loss: 0.1017 - accuracy: 0.9661"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c81feb6d077a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 50\n",
    "\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = finetune.fit(train_generator,\n",
    "                    validation_data = valid_generator,\n",
    "                    epochs = total_epochs,\n",
    "                    steps_per_epoch = generator_tra1.n//batch_size,\n",
    "                    validation_steps = generator_val1.n//batch_size,\n",
    "                    initial_epoch= history.epoch[-1],\n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = callbacks_list\n",
    "                    )\n",
    "\n",
    "finetune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.7, 1])\n",
    "plt.plot([101,101],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.5])\n",
    "plt.plot([101,101],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('mult_finetune_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune.save('./Sunspot_traindata_models_and_features/model_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make model == feature model\n",
    "# feature_model = keras.applications.DenseNet201(weights=\"imagenet\", include_top=False)\n",
    "# feature_model.trainable= False\n",
    "weight_path=\"testmodel/best_multi_finetuned.h5\"\n",
    "model3 = build_finetuning(model2)\n",
    "# 가중치 로드\n",
    "model3.load_weights(weight_path)\n",
    "\n",
    "# model3.save('./Sunspot_traindata_models_and_features/best_tuned_Adam_hsv.h5')\n",
    "# 모델 평가\n",
    "# valid_generator = two_image_generator(generator_val1,generator_val2) # 초기화\n",
    "# model3.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('testmodel/best_multi_finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
